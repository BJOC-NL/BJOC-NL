<!DOCTYPE html>
<html lang="en">

<head>
    <link rel="icon" href="../../BJOC-NL-logo.png" type="image/png">
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <script type="text/javascript" src="../../js+css/llab/loader.js"></script>
    <script type="text/javascript" src="../../js+css/gifffer.min.js"></script>
    <script type="text/javascript">
        window.onload = function () {
            Gifffer();
            Inhoudsopgave();
        }
    </script>
    <link rel="stylesheet" type="text/css" href="../../js+css/css/bjc-gifffer.css">
    <title>Hoofdstuk 6 Les 1: De Hiërarchie van Computer-abstractie, Pagina 6</title>
</head>

<body>
    <div class="full">
        <h2>Het Digitale Domein: Architectuur</h2>

        <div class="learn"><strong>Op deze pagina</strong>, gaan we in plaats avn naar software naar hardware kijken.
            Het eerste onderwerp is
            <em>architectuur,</em> wat praktisch is hoe de software de hardware ziet.</div>

        <p> De software in een computer is nutteloos zonder de <em>hardware:</em> de daadwerkelijke circuits in de
            computer. Net zoals er lagen van abstractie zijn voor software denken hardware-designers ook in lagen van
            abstractie.
        </p>
        <img class="imageRight noshadow" src="/bjc-r/img/6-computers/hardware-abstraction-mini.png"
            alt="Geen Afbeelding" />
        <p>Iedereen heeft het over computers die alle gegevens vertegenwoordigen met slechts twee waarden, 0 en 1. Maar
            dat is niet echt hoe elektronische circuits werken. Computerontwerpers kunnen doen <em> alsof </em>
            circuits uit (0) of aan (1) staan vanwege <strong> digitale abstractie </strong>, de belangrijkste
            abstractie in hardware. Boven dat abstractieniveau zijn er vier gedetailleerdere niveaus, het
            <strong> digitale domein </strong> genoemd. Onder de digitale abstractie werken ontwerpers in het
            <strong> analoge domein </strong>, waarin een draad in een circuit elke spanningswaarde kan hebben, niet
            slechts twee waarden. </p>
        <p> Op de volgende vier pagina's, zullen we vier lagen van het digitale domein verkennen. </p>

        Everyone talks about computers representing all data using only two values, 0 and 1. But that's not really
        how electronic circuits work. Computer designers can work <em>as if</em> circuits were either off (0) or on
        (1) because of the <strong>digital abstraction</strong>, the most important abstraction in hardware. Above
        that level of abstraction, there are four more detailed levels, called the <strong>digital domain</strong>.
        Below the digital abstraction, designers work in the <strong>analog domain</strong>, in which a wire in a
        circuit can have any voltage value, not just two values.</p>
        <p>On the next four pages, we'll explore four levels of the digital domain.</p>

        <div class="endnote">
            <h3>De Stored program-computer (Computer met opgeslagen programma)</h3>
            <p>Zoals je zal zien in Les 3 zijn er al duizenden jaren machines die berekeningen uitvoeren. Maar de
                moderne, <em>programmeerbare</em> computer komt voort uit het werk van Charles Babbage in de vroege
                jaren van 1800.
            </p>
            <p> Babbage was vooral een wiskundige maar hij heeft veel bijgedragen aan onder andere astronomie en
                economie. Babbage leefde ongeveer 150 jaar geleden van 1791-1871. Dat elektriciteit als een bron van
                energie kon worden gebruikt was nog onbekend. De stoommachine werd populair rond de tijd dat hij was
                geboren. De meeste precieze machines uit zijn tijd waren uurwerken.

                Babbage was mainly a mathematician, but he contributed to fields as varied as astronomy and economics.
                Babbage lived about 150 years ago from 1791-1871. Electricity as a source of energy was unknown. The
                steam engine came into widespread use around the time he was born. The most precise machinery of his
                time was clockwork—gears.</p>

            <h4><strong>De Difference Engine</strong></h4>
            <p>Babbage's eerste computer was de Difference Engine (Verschilmotor).Hij gebruikten tandwielen om een
                ingewikkelde machine te ontwerpen die tabellen met getallen kon berekenen en printen (bijvoorbeld
                tabellen van logaritme functies). Maar deze tandwielen moesten heel precies zijn en ieder tandwiel moest
                met de hand gemaakt worden. Het project werd zo duur dat de overheid de financiering stop zetten en
                Babbage maakte het project nooit af.
            </p>
            <table class="indent">
                <tr>
                    <td>
                        <img src="/bjc-r/img/6-computers/babbage-difference-engine.jpg" height="200px"
                            alt="Geen Afbeelding" /><br />
                        <small>De Difference Engine in het London Science Museum</small><br />
                        <small><small>
                                Afbeelding van Wikimedia-gebruiker geni. Copyright 2008. Licentie: GFDL, CC BY-SA.
                            </small></small>
                    </td>
                    <td>
                        <img src="/bjc-r/img/6-computers/closeup-difference-eng.jpg" height="200px"
                            alt="Geen Afbeelding" /><br />
                        <small>Een close-up die de tandwielen duidelijker laat zien</small><br />
                        <small><small>
                                Afbeelding van Carsten Ullrich. Copyright 2005. Licentie: CC-BY-SA-2.5.
                            </small></small>
                    </td>
                </tr>
            </table>

            <p>
                <a href="#hint-difference" data-toggle="collapse">
                    Leer meer over de geschiedenis van de Difference Engine.
                </a>
                <div id="hint-difference" class="collapse">

                    <p> In de tijd van Babbage werden dergelijke numerieke tabellen met de hand berekend door menselijke
                        wiskundigen, en ze werden met de hand gezet om te worden afgedrukt. Zowel de berekening als het
                        kopiëren naar print waren foutgevoelig, en nauwkeurige tabellen waren nodig voor doeleinden
                        variërend van engineering tot navigatie. </p>
                    <p> Babbage bouwde eerst een kleine Difference Engine in 1822. Deze eerste poging bewees dat een
                        Difference Engine mogelijk was, maar het had niet de precisie (aantal cijfers voor elk getal) om
                        praktisch te zijn. In 1823 financierde de Britse overheid Babbage om een ​​grotere versie te
                        bouwen. Helaas konden metaalsmeden in zijn tijd niet erg precieze tandwielen in grote
                        hoeveelheden produceren; elk moest handgemaakt zijn. Dus had hij hij tien keer zijn
                        goedgekeurde budget besteed tegen de tijd dat de overheid het project in 1842 stopzette.</p>
                    <p> In 1991 voltooide het London Science Museum een Difference Engine volgens het oorspronkelijke
                        ontwerp van Babbage met behulp van tandwielen gemaakt door moderne processen, maar op het niveau
                        van precisie dat beschikbaar was voor Babbage. Dit bewees dat Babbage in principe een werkende
                        machine had kunnen voltooien met voldoende tijd en geld. </p>
                </div>
            </p>

            <h4><strong>De Analytical Engine</strong></h4>
            <p> De Difference Engine kan worden gebruikt om veel verschillende functies te berekenen door de
                startpositie van verschillende versnellingen handmatig in te stellen. Maar het had
                <strong> slechts één algoritme </strong>: het algoritme ingebouwd in het hardware-ontwerp. In 1833 begon
                Babbage te werken aan de Analytical Engine, die gebaseerd was op het algemene idee van de Difference
                Engine maar die wel <strong> instructies uit kon voeren </strong> in een primitieve programmeertaal die
                met ponskaarten werkten. <br />
                <div class="sidenote">
                    <small>Ponskaarten gebruikt om de Analytical Engine te programmeren</small><br />
                    <small><small>Karoly Lorentey. Copyright 2004. Licentie: CC-BY.</small></small>
                </div>
                <img class="indent" src="/bjc-r/img/6-computers/punched-cards-analytical-engine.jpg" height="300px"
                    alt="Geen Afbeelding" />
            </p>

            <p> Tegenwoordig zijn we omringd door programmeerbare computers en het is nu vanzelfsprekend om software
                te hebben. Maar dit was niet altijd zo, vóór Babbage werden alle algoritmen rechtstreeks in hardware
                geïmplementeerd. </p>
            <p> Dus, 150 jaar geleden, maakte Babbage plannen voor wat in wezen een moderne computer is, hoewel hij geen
                elektronica beschikbaar had. Zijn onderliggende idee voor hardware was volledig mechanisch, maar het
                bleek niet mogelijk te zijn om het met de toenmalige technologie te bouwen. We hebben geen
                <em> bruikbare </em> computers gekregen totdat er een onderliggende technologie was die klein,
                goedkoop en snel genoeg was om de software-abstractie te ondersteunen. Je leert snel over deze
                technologie, transistors. </p>
        </div>

        <div class="takeNote">The abstraction of <em>software</em> (a program stored in the computer's memory) is what
            makes a computer usable for more than one purpose.</div>

        <div class="endnote">
            <p>
                <a href="#hint-analytical" data-toggle="collapse"> Leer meer over de Analytical Engine.</a>
                <div id="hint-analytical" class="collapse">
                    <p>De Analytical Engine, had net als moderne computers, een rekenkundige processor (genaamd de
                        "molen") en een apart geheugen (de "winkel") die 1000 getallen kon bijhouden, ieder tot en met
                        40
                        cijfers. De molen voerde rekenkundige handelingen uit in decimalen (met cijfers 0-9 verdeeld
                        over ieder tandwiel); het gebruik van "enen en nullen" kwam pas later.
                    </p>
                    <p>De programmeertaal die gebruikt werd in de Analytical Engine had ook condities en lussen, wat
                        alles is dat je nodig hebt om een algoritme te maken. (Het kon lussen maken omdat het voorwaarts
                        en achterwaarts door de ponskaarten kon gaan.)
                    </p>
                    <p>Helaas kon Babbage maar een klein deel van de Analytical Engine bouwen, die nog meer metaalwerk
                        nodig had dan de Difference Engine. Zijn aantekeningen over het ontwerp waren niet volledig en
                        dus heeft niemand ooit een werkend model gebouwd, alhoewel er simulaties zijn op het internet
                        (zie het Ga Een Stapje Verder-probleem hieronder). Jammer genoeg was Babbage werk niet bekend in
                        de vroege dagen van elektronische computers en veel mensen hebben zijn ideeën heruitgevonden.
                    </p>
                </div>
            </p>
            <p>
                <a href="#hint-ada" data-toggle="collapse">Leer over Ada, Gravin Lovelace's uitvinding van symbolisch
                    programmeren.
                </a>
                <div id="hint-ada" class="collapse">
                    <p> Alhoewel zijn ontwerp zeer veelzijdig was, was Babbage vooral geïnteresseerd
                        in het afdrukken van getallentabellen. Het was zijn medewerker Augusta Ada King-Noel, gravin van
                        Lovelace, die voor het eerst inzag dat de nummers in de computer van Babbage niet alleen als
                        hoeveelheden konden worden gebruikt, maar ook als weergave van muzieknoten, letters,
                        enzovoort. </p>
                    <img class="indent" height="300px" src="/bjc-r/img/6-computers/ada-lovelace.jpg"
                        alt="Geen Afbeelding" />
                    <div class="sidenote">
                        <small>Afbeelding van Alfred Edward Chalon, Science &amp; Society Picture Library, Publiek
                            Domein, via
                            Wikimedia.</small>
                    </div>

                    <p> Veel van wat we vandaag weten over het ontwerp van Babbage komt uit de uitgebreide aantekeningen
                        van Ada Lovelace over zijn ontwerp. Haar aantekeningen omvatten het eerste <em> gepubliceerde
                        </em> programma voor de Analytical Engine, en daarom wordt ze algemeen beschouwd als "de eerste
                        programmeur", hoewel het bijna zeker is dat Babbage zelf verschillende voorbeeldprogramma's
                        heeft geschreven tijdens het ontwerpen van de machine. </p>
                    <p> Of ze nu echt de eerste programmeur was of niet, historici zijn het erover eens dat ze iets
                        belangrijkers heeft gedaan: ze heeft het idee van <em> symbolische </em> berekening
                        (inclusief tekst, afbeeldingen, muziek, etc.) naar numerieke berekening uitgevonden. Dit
                        inzicht maakte de weg vrij voor alle manieren waarop computers tegenwoordig worden gebruikt,
                        van Netflix tot stem-interactieve programma's zoals Siri en Alexa. </p>
                </div>
            </p>
        </div>

        <h3>What's an Architecture?</h3>
        <p>The Analytical Engine (described above) was the first programmable computer architecture. The processor in
            the computer you are using today understands only one language, its own <em>machine language</em>&mdash;not
            Java, not C, not Snap<em>!</em>, not Python, nor anything else. Programs written in those other languages
            must first be translated into machine language.</p>
        <p>The most important part of the architecture is the machine language, the set of ultra-low-level instructions
            that the hardware understands. This language is like a contract between the hardware and the software: The
            hardware promises to understand a set of instructions, and the software compiles programs from
            human-friendly language into those instructions.</p>
        <div class="vocabFullWidth">
            <p><strong>Machine language</strong> is the lowest-level programming language; it is directly understood by
                the computer hardware.</p>
            <p><strong>Architecture</strong> is an abstraction, a specification of the machine language. It also tells
                how the processor connects to the memory. It doesn't specify the circuitry; the same architecture can be
                built as circuitry in many different ways.</p>
        </div>
        <p>One important part of an architecture is the number of wires that connect the processor and memory. This is
            called the <em>width</em> of the architecture, measured in <em>bits</em> (number of wires). A wider computer
            can process more data in one instruction.</p>

        <div class="endnote">
            <a href="#hint-machine-language" data-toggle="collapse">What does machine language look like?</a>
            <div id="hint-machine-language" class="collapse">
                <p>
                    Consider the Snap<em>!</em> instruction <img class="inline nopad"
                        src="/bjc-r/img/6-computers/set-c-to-a+b.png" alt="Geen Afbeelding" />. In a lower-level
                    language such as C or Java, the same idea would be written as:<br />
                    <pre>c = a+b;</pre>
                    That simple command might be translated into <em>six</em> machine language instructions (slightly
                    simplified here):<br />
                    <pre>movq    _c, %rcx
movq    _b, %rdx
movq    _a, %rsi
movl    (%rsi), %edi
addl    (%rdx), %edi
movl    %edi, (%rcx)</pre>
                    This notation, called <em>assembly language</em>, is a line-by-line equivalent to the actual numeric
                    instruction codes but is slightly more readable.
                </p>
                <a href="#hint-assembly" data-toggle="collapse">What does that code mean?</a>
                <div id="hint-assembly" class="collapse">
                    <p>The first three instructions load the <em>addresses</em> of the three variables into registers
                        inside the processor. The names with percent signs, such as <code>%rcx</code>, refer to specific
                        processor registers. <code>Movq</code> is the name of a machine language instruction. (It
                        abbreviates "move quote," which says to move a constant value into a register. Note that
                        <var>a</var> is a variable, but <em>the address of</em> <var>a</var> is a constant value — the
                        variable doesn't move around in the computer's memory.)</p>
                    <p>The next instruction, <code>movl</code> ("move long"), says to move a word from one place to
                        another. Putting a register name in parentheses, like <code>(%rsi)</code>, means to use the
                        memory location whose address is in the register. In this case, since the third
                        <code>movq</code> put the address of <var>a</var> into register <code>%rsi</code>, the first
                        <code>movl</code> says to move the variable <var>a</var> from memory into a processor register.
                        Then the <code>addl</code> instruction says to add the variable <var>b</var> into that same
                        register. Finally, the value in register <code>%edi</code> is moved into the memory location
                        containing variable <var>c</var>.</p>
                </div>
                <p>You wouldn't want to have to program in this language! And you <em>don't</em> have to; modern
                    architectures are designed for compilers, not for human machine language programmers.</p>
            </div>
        </div>
        <div class="endnote">
            Learn about:
            <ul>
                <li>
                    <a href="#hint-architecture" data-toggle="collapse">PC/Mac architecture</a>
                    <div id="hint-architecture" class="collapse">
                        <div class="comment" style="color:grey">This has a lot of numbers in it which make it harder to
                            read, but more importantly it's so abstract and doesn't really talk about anything familiar,
                            which given the hint title "PC/Mac" I was expecting. Needs some work. --MF, 11/8/17</div>
                        <p>
                            Most computer processors (the part that carries out instructions) in desktop or laptop
                            computers use an architecture called "x86" that was designed at Intel, a chip manufacturer.
                            The first processor using that architecture was called the 8086, released in 1978. (The
                            reason for the name x86 is that the first few improved versions were called 80286, 80486,
                            and so on.) The original 8086 was a 16-bit architecture; since then 32-bit (since 1985) and
                            64-bit (since 2003) versions have been developed. Even with all the refinements of the
                            architecture, the new x86 processors are almost always <em>backward compatible,</em> meaning
                            that today's versions will still run programs that were written for the original 8086.
                        </p>
                        <p>
                            Why did the x86 architecture come to rule the world? The short answer is that IBM used it in
                            their original PC, and all the later PC manufacturers followed their lead because they could
                            run IBM-compatible software unmodified. But why did IBM choose the x86? There were arguably
                            better competing architectures available, such as the Motorola 68000 and IBM's own 801. The
                            PC designers argued about which to use, but in the end, what made the difference was IBM's
                            long history of working with Intel.
                        </p>
                        <p>
                            The Apple Macintosh originally used the Motorola 68000 architecture, and in 1994 Apple
                            designed its own PowerPC architecture in a joint project with IBM and Motorola, but in 2006
                            they, too, switched to the x86, because Intel keeps producing newer, faster versions of the
                            x86 more often than other companies could keep up.
                        </p>
                    </div>
                </li>
                <li>
                    <a href="#hint-architecture-phone" data-toggle="collapse">smartphone architecture</a>
                    <div id="hint-architecture-phone" class="collapse">
                        <p>Everything about smartphone architecture is determined by the tiny size of the space inside
                            the case. The height and width of the phone are constrained by the size of people's front
                            pockets. <em>(Don't keep your phone in your back pants pocket. That's really bad both for
                                the phone and for your back.)</em> The front-to-back depth of a phone could be much
                            bigger than it is, but for some reason phone manufacturers compete on the thinness of their
                            phones, which gives designers even less room inside.</p>
                        <p>As a result, many components that would be separate from the processor chip in a computer are
                            instead part of the same chip in a phone. These components may include some or all of a
                            cellular modem, a WiFi modem, a graphics processor (another processor that specializes in
                            parallel arithmetic on lists of numbers), memory, a GPS receiver to find your phone's
                            physical location, circuitry to manage the power depletion and recharging of the battery,
                            and more. These days, the chip is likely to include two, four, or even eight copies of the
                            actual CPU, to make multicore systems. This collection of components is called a <em>system
                                on a chip,</em> or SoC.</p>
                        <p>Intel made an x86-based (that is, the same architecture used in PCs) low-power SoC called the
                            Atom, which was used in a few Motorola phones and some others made by companies you've never
                            heard of. It was made to support Android, Linux, and Windows phones.</p>
                        <p>But the vast majority of phones use the ARM architecture, which (unlike the x86) was designed
                            from the beginning to be a low-power architecture. The acronym stands for Advanced RISC
                            Machine. It's available in 32-bit and 64-bit configurations.</p>
                        <div class="endnote">
                            <a href="#hint-risc" data-toggle="collapse">What's a RISC?</a>
                            <div id="hint-risc" class="collapse">
                                <p>The name stands for Reduced Instruction Set Computer, as opposed to the CISC (Complex
                                    Instruction Set Computer) architectures, including the x86. The <em>instruction
                                        set</em> of an architecture is, as you'd guess from the name, the set of
                                    instructions that the processor understands. A RISC has fewer instructions than a
                                    CISC, but it's simpler in other ways also. For example, a CISC typically has more
                                    <em>addressing modes</em> in its instructions. In the x86 architecture, the
                                    <code>add</code> instruction can add two processor registers, or a register and a
                                    value from the computer's memory, or a constant value built into the instruction
                                    itself. A RISC architecture's <code>add</code> instruction just knows how to add two
                                    registers (perhaps putting the result into a third register), and there are separate
                                    <code>load</code> and <code>store</code> instructions that copy values from memory
                                    to register or the other way around. Also, in a RISC architecture, all instructions
                                    are the same length (say, 32 bits) whereas in a CISC architecture, instruction
                                    lengths may vary. These differences matter because a RISC can be loading the next
                                    instruction before it's finished with the previous instruction, and a RISC never has
                                    more than one memory data reference per instruction.</p>
                                <p>So why don't they use a RISC architecture in PCs? At one time Apple used a RISC
                                    processor called the PowerPC in its Macintosh computers, but the vast majority of
                                    computers sold are PCs, not Macs, and as a result Intel spends vast sums of money on
                                    building faster and faster circuits implementing the x86 architecture. The moral is
                                    about the interaction between different levels of abstraction: A better architecture
                                    can be overcome by a better circuit design or better technology to cram components
                                    into an integrated circuit.</p>
                            </div>
                        </div>
                        <p>The company that designed the ARM, called ARM Holdings, doesn't actually build processors.
                            They license either the architecture design or an actual circuit design to other companies
                            that integrate ARM processors into SoCs. Major companies that build ARM-based processor
                            chips include Apple, Broadcom, Qualcomm, and Samsung. Smartphone manufacturers buy chips
                            from one of these companies.</p>
                    </div>
                </li>
                <li>
                    <a href="#hint-architecture-iot" data-toggle="collapse">embedded architecture and the "Internet of
                        Things"</a>
                    <div id="hint-architecture-iot" class="collapse">
                        <p>You can buy thermostats with computers in them, refrigerators with computers in them, fuzzy
                            animal toys with computers in them—more and more things, as time goes on. Modern automobiles
                            have <em>several</em> computers in them, largely for safety reasons; you wouldn't want the
                            brakes to fail because the DVD player has a problem. The goal, as described by researchers
                            in computing, is "smart dust," meaning that lots of computers could be floating around a
                            building unnoticed. What good is an unnoticed computer? This is a classic dual use
                            technology. The beneficial use everyone talks about is emergency response to disasters; it
                            would be a great help to the fire department to know, from the outside, which rooms of a
                            building have people in them. But another use for this technology would be spying.</p>
                        <p class="indent">
                            <img src="/bjc-r/img/6-computers/freescale_scmimx6d-sm.jpg" alt="Geen Afbeelding"><br />
                            <small><small>NXP Freescale SCM-i.MX6D chip</small></small>
                        </p>
                        <p>For embedded computing, the main design criteria are small size and low power consumption.
                            The chip in the picture above is based on the ARM architecture, like most cell phones.
                            That's actually a <em>big</em> embedded-systems chip; the Kinetis KL02 MCU (micro controller
                            unit) fits in a 2 millimeter square—less than 1/10 inch. That's still too big to float in
                            the air like dust, but imagine it in a sticky container and thrown onto the wall.</p>
                        <p>Someday, the spying will be even more effective (along with, we hope, treatment for diseases
                            of the brain): <a
                                href="https://www.engadget.com/2017/05/17/arm-targets-your-brain-with-new-implantable-chips/"
                                target="_blank">ARM targets your brain with new implantable chips</a> (Engadget,
                            5/17/2017).</p>
                        <p>Intel made a button-sized x86-compatible chip in 2015, but announced in 2017 that it would be
                            discontinued, leaving only ARM and PowerPC-based processors competing in this market.</p>
                    </div>
                </li>
                <li>
                    <a href="#hint-architecture-hobby" data-toggle="collapse">hobbyist computer architecture</a>
                    <div id="hint-architecture-hobby" class="collapse">
                        <p>In one sense, <em>any</em> architecture can be a hobbyist architecture. Even back in the days
                            of million-dollar computers, there were software hobbyists who found ways to get into
                            college computer labs, often by making themselves useful there. Today, there are much more
                            powerful computers that are cheap enough that hobbyists are willing to take them apart. But
                            there are a few computer architectures <em>specifically</em> intended for use by hobbyists.
                        </p>
                        <div class="comment">We DO NOT yet have permissions for this image. --MF, 12/4/17</div>
                        <img class="imageRight" src="/bjc-r/img/6-computers/arduino.jpg" alt="Geen Afbeelding" />
                        <p>By far the most popular computer specifically for hobbyists is the Arduino. It's a circuit
                            board, not just a processor. Around the edges of the board are connectors. On the short edge
                            on the left in the picture are the power input, which can connect to a power supply plugged
                            into the wall or to a battery pack for a mobile device such as a robot, and a USB connector
                            used mainly to download programs from a desktop or laptop computer. On the long edges are
                            connectors for single wires connected to remote sensors (for light, heat, being near a wall,
                            touching another object, etc.) or actuators (stepping motors, lights, buzzers, etc.).</p>
                        <p>One important aspect of the Arduino design is that it's <em>free</em> ("free as in freedom").
                            Anyone can make and even sell copies of the Arduino. This is good because it keeps the price
                            down (the basic Arduino Uno board costs $22) and encourages innovation, but it also means
                            that there can be incompatible Arduino-like boards. (The name "Arduino" is a trademark that
                            can be used only by license from Arduino AG.)</p>
                        <p>The processor in most Arduino models is an eight-bit RISC system with memory included in the
                            chip, called the AVR, from a company called Atmel. It was designed by two (then) students in
                            Norway, named Alf-Egil Bogen and Vegard Wollan. Although officially "AVR" doesn't stand for
                            anything, it is widely believed to come from "Alf and Vegard's RISC." There are various
                            versions of the AVR processor, with different speeds, memory capacities, and of course
                            prices; there are various Arduino models using the different processors.</p>
                        <p>Unlike most ("von Neumann architecture") computers, the AVR ("Harvard architecture")
                            separates program memory from data memory. (It actually has <em>three</em> kinds of memory,
                            one for the running program, one for short-term data, and one for long-term data.) Babbage's
                            Analytical Engine was also designed with a program memory separate from its data memory.</p>
                        <div class="endnote">
                            <a href="#hint-Harvard" data-toggle="collapse">Why would you want more than one kind of
                                memory?</a>
                            <div id="hint-Harvard" class="collapse">
                                <p>
                                    There are actually two different design issues at work in this architecture. One is
                                    all the way down in the analog domain, having to do with the kind of physical
                                    circuitry used. There are <em>many</em> memory technologies, varying in cost, speed,
                                    and <em>volatility:</em> volatile memory loses the information stored in it when the
                                    device is powered off, while non-volatile memory retains the information. Here's how
                                    memory is used in the AVR chips:
                                    <ul>
                                        <li>
                                            <strong>EEPROM</strong> (512 Bytes–4kBytes) is non-volatile, and is used for
                                            very long term data, like a file in a computer's disk, except that there is
                                            only a tiny amount available. Programs on the Arduino have to ask explicitly
                                            to use this memory, with an EEPROM library.
                                            <ul>
                                                <li>The name stands for Electrically Erasable Programmable Read-Only
                                                    Memory, which sounds like a contradiction in terms. In the early
                                                    days of transistor-based computers, there were two kinds of memory,
                                                    volatile (Random Access Memory, or RAM) and nonvolatile (Read-Only
                                                    Memory, or ROM). The values stored in an early ROM had to be built
                                                    in by the manufacturer of the memory chip, so it was expensive to
                                                    have a new one made. Then came Programmable Read-Only Memory (PROM),
                                                    which was read-only once installed in a computer, but could be
                                                    programmed, once only, using a machine that was only somewhat
                                                    expensive. Then came EPROM, Erasable PROM, which could be erased in
                                                    its entirety by shining a bright ultraviolet light on it, and then
                                                    reprogrammed like a PROM. Finally there was Electrically Erasable
                                                    PROM, which could be erased while installed in a computer, so
                                                    essentially equivalent to RAM, except that the erasing is much
                                                    slower than rewriting a word of RAM, so you use it only for values
                                                    that aren't going to change often.</li>
                                            </ul>
                                        </li>
                                        <li>
                                            <strong>SRAM</strong> (1k–4kBytes): This memory can lose its value when the
                                            machine is turned off; in other words, it's volatile. It is used for
                                            temporary data, like the script variables in a Snap<em>!</em> script.
                                            <ul>
                                                <li>The name stands for Static Random Access Memory. The "Random Access"
                                                    part differentiates it from the magnetic tape storage used on very
                                                    old computers, in which it took a long time to get from one end of
                                                    the tape to another, so it was only practical to write or read data
                                                    in sequence. Today all computer memory is random access, and the
                                                    name "RAM" really means "writable," as opposed to read-only. The
                                                    "Static" part of the name means that, even though the memory
                                                    requires power to retain its value, it <em>doesn't</em> require
                                                    periodic refreshing as regular ("Dynamic") computer main memory
                                                    does. ("Refreshing" means that every so often, the computer has to
                                                    read the value of each word of memory and rewrite the same value, or
                                                    else it fades away. This is a good example of computer circuitry
                                                    whose job is to maintain the <em>digital abstraction,</em> in which
                                                    a value is zero or one, and there's no such thing as "fading" or
                                                    "in-between values.") Static RAM is faster but more expensive than
                                                    dynamic RAM; that's why DRAM is used for the very large (several
                                                    gigabytes) memories of desktop or laptop computers.</li>
                                            </ul>
                                        </li>
                                        <li>
                                            <strong>Flash</strong> memory (16k–256kBytes): This is the main memory used
                                            for programs and data. Flash memory is probably familiar to you because it's
                                            used for the USB sticks that function as portable external file storage.
                                            It's technically a kind of EEPROM, but with a different physical
                                            implementation that makes it much cheaper (so there can be more of it in the
                                            Arduino), but more complicated to use, requiring special control circuitry
                                            to maintain the digital abstraction.
                                            <ul>
                                                <li>"More complicated" means, for example, that changing a bit value
                                                    from 1 to 0 is easy, but changing it from 0 to 1 is a much slower
                                                    process that involves erasing a large block of memory to
                                                    <em>all</em> 1 bits and then rewriting the values of the bits you
                                                    didn't want to change.</li>
                                            </ul>
                                        </li>
                                    </ul>
                                </p>
                                <p>So, that's why there are physically different kinds of memory in the AVR chips, but
                                    none of that completely explains the Harvard architecture, in which memory is
                                    divided into <em>program</em> and <em>data,</em> regardless of how long the data
                                    must survive. The main reason to have two different memory interface circuits is
                                    that it allows the processor to read a program instruction and a data value <em>at
                                        the same time.</em> This can in principle make the processor twice as fast,
                                    although that much speed gain isn't found in practice.</p>
                                <p>To understand the benefit of simultaneous instruction and data reading, you have to
                                    understand that processors are often designed using an idea called
                                    <em>pipelining.</em> The standard metaphor is about doing your laundry, when you
                                    have more than one load. You wash the first load, while your dryer does nothing;
                                    then you <em>wash the second load while drying the first load, </em>and so on until
                                    the last load. Similarly, the processor in a computer includes circuitry to decode
                                    an instruction, and circuitry to do arithmetic. If the processor does one thing at a
                                    time, then at any moment either the instruction decoding circuitry or the arithmetic
                                    circuitry is doing nothing. But if you can read the next instruction at the same
                                    time as carrying out the previous one, all of the processor is kept busy.</p>
                                <p>This was a long explanation, but it's still vastly oversimplified. For one thing,
                                    it's possible to use pipelining in a von Neumann architecture also. And for another,
                                    a <em>pure</em> Harvard architecture wouldn't allow a computer to load programs for
                                    itself to execute. So various compromises are used in practice.</p>
                            </div>
                        </div>
                        <p>Atmel has since introduced a line of ARM-compatible 32-bit processors, and Arduino has boards
                            using that processor but compatible with the layout of the connectors on the edges.</p>
                        <p>One thing that has contributed to the popularity of the Arduino with hobbyists is the
                            availability of <em>shields,</em> which are auxiliary circuit boards that plug into the side
                            edge connectors and have the same connectors on their top side. Shields add features to the
                            system. Examples are motor control shields, Bluetooth shields for communicating with cell
                            phones, RFID shields to read those product tags you find inside the packaging of many
                            products, and so on. Both the Arduino company and others sell shields.</p>
                        <div class="sidenote">
                            <small>Stack of Arduino shields</small><br />
                            <small><small>Image by Wikimedia user Marlon J. Manrique, CC-BY-SA 2.0.</small></small>
                        </div>
                        <img class="indent" src="/bjc-r/img/6-computers/arduino-shields.jpg" width="250px"
                            alt="Geen Afbeelding" />
                        <p>A completely different hobbyist architecture is the <em>Raspberry Pi.</em> It was designed to
                            be used like a desktop or laptop computer, but with more access to its electronics. It uses
                            an ARM-compatible processor, like most cell phones, but instead of running phone operating
                            system software such as Android, it runs "real" computer besturingssystemen. It ships with
                            Linux, but people have run Windows on it.</p>
                        <p>The main thing that makes it exciting is that it's inexpensive: different models range in
                            price from $5 to $35. That price includes just the circuit board, as in the picture, without
                            a keyboard, display, mouse, power adapter, or a case. The main expense in kit computers is
                            the display, so the Pi is designed to plug into your TV. You can buy kits that include a
                            minimal case, a keyboard, and other important add-ons for around $20. You can also buy fancy
                            cases to make it look like any other computer, with a display, for hundreds of dollars.</p>
                        <p>Because the Pi is intended for educational use, it comes with software, some of which is free
                            for anyone, but some of which generally costs money for non-Pi computers. One important
                            example is Mathematica, which costs over $200 for students (their cheapest price), but is
                            included free on the Pi.</p>
                        <p>Like the Arduino, the Pi supports add-on circuit boards with things like sensors and wireless
                            communication modules.</p>
                        <div class="sidenote">
                            <small>Raspberry Pi board</small><br />
                            <small><small>Image by Evan Amos, via Wikimedia, public domain</small></small>
                        </div>
                        <img class="indent" src="/bjc-r/img/6-computers/raspberry-pi.jpg" width="250px"
                            alt="Geen Afbeelding" />
                    </div>
                </li>
            </ul>
        </div>
        <div class="endnote">
            <a href="#hint-architecture-general" data-toggle="collapse">Learn more about computer architecture in
                general.</a>
            <div id="hint-architecture-general" class="collapse">

                <h4>The memory hierarchy</h4>
                <p>For a given cost of circuit hardware, <strong>the bigger the memory, the slower it works.</strong>
                    For this reason, computers don't just have one big chunk of memory. There will be a small number of
                    <em>registers</em> inside the processor itself, usually between 8 and 16 of them. The "size" (number
                    of bits) of a data register is equal to the width of the architecture.</p>
                <p>The computer's main memory, these days, is measured in GB (gigabytes, or billions of bytes). A memory
                    of that size can't be fast enough to keep up with a modern processor. Luckily, computer programs
                    generally have <em>locality of reference,</em> which means that if the program has just made use of
                    a particular memory location, it's probably going to use a nearby location next. So a complete
                    program may be very big, but over the course of a second or so only a small part of it will be
                    needed. Therefore, modern computers are designed with one or more <em>cache</em> memories—much
                    smaller and therefore faster—between the processor and the main memory. The processor makes sure
                    that the most recently used memory is copied into the cache. </p>
                <p>One recent 64-bit x86 processor has a first level (L1) cache of 64KB (thousands of bytes) inside the
                    processor chip, a larger but slower L2 cache of 256 KB, also inside the processor, and an L3 cache
                    of up to 2 MB (megabytes, millions of bytes) outside the processor. Each level of cache has a copy
                    of the most recently used parts of the next level outward: the L1 cache copies part of the L2 cache,
                    which copies part of the L3 cache, which copies part of the main memory. Data in the L1 cache can be
                    accessed by the processor about as fast as its internal registers, and each level outward is a
                    little slower. Hardware in the processor handles all this complexity, so that programmers can write
                    programs as if the processor were directly connected to the main memory.</p>
                <h4>Second sourcing</h4>
                <p>Intel licenses other chip manufacturers to build processors that use the same architecture as Intel's
                    processors. Why do they do that? Wouldn't they make more money if people had to buy from Intel? The
                    reason is that computer manufacturers, such as Dell, Apple, and Lenovo, won't build their systems
                    around an architecture that is only available from one company. They're not worried that Intel will
                    go out of business; the worry is that there may be a larger-than-expected demand for a particular
                    processor, and Intel may not be able to fill orders on time. But if that processor is also available
                    from other companies such as AMD and Cyrix, then a delay at Intel won't turn into a delay at Dell.
                    Those other chip manufacturers may not use the same circuitry as the Intel version, as long as they
                    behave the same at the architecture level.</p>
            </div>
        </div>
        <div class="takeItFurther">
            <ol type="A">
                <li>
                    Learning enough about the Analytical Engine to be able to write even a <em>simple</em> program for
                    it is quite a large undertaking. Don't try it until after the AP exam, but if you are interested,
                    there are extensive online resources available here:
                    <ul>
                        <li><a href="http://www.fourmilab.ch/babbage/contents.html" target="_blank">The Analytical
                                Engine Table of Contents</a></li>
                        <li><a href="http://www.fourmilab.ch/babbage/emulator.html" target="_blank">Web Analytical
                                Engine Emulator</a></li>
                    </ul>
                </li>
            </ol>
        </div>
    </div>
    <div class="full-bottom-bar" style="background-position: 20px 3px;">
        <div class="bottom-nav btn-group"> <a class="btn btn-default backbutton arrow" style="min-width: 90px;"
                href="H6L1P5.html">Terug</a> <a class="btn btn-default forwardbutton arrow" style="min-width:90px;"
                href="H6L1P7.html">Volgende</a> </div>
    </div>

</body>

</html>